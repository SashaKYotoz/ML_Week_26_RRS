{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-27T16:12:26.333548500Z",
     "start_time": "2026-01-27T16:12:09.251984100Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import json\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class CoffeeRecommender:\n",
    "    def __init__(self, recipes_path, users_path, train_path, cold_users_path):\n",
    "        \"\"\"\n",
    "        Hybrid Recommender System optimized for NDCG@5.\n",
    "        Strategies:\n",
    "        - Cold Users: Content-Based Filtering (Taste Matching) + Popularity Boost\n",
    "        - Warm Users: Weighted Hybrid of SVD (Collaborative) + History-Based Content Profile\n",
    "        \"\"\"\n",
    "        # Load Data\n",
    "        self.recipes = pd.read_csv(recipes_path)\n",
    "        self.users = pd.read_csv(users_path)\n",
    "        self.interactions = pd.read_csv(train_path)\n",
    "\n",
    "        # Load Cold Users\n",
    "        try:\n",
    "            with open(cold_users_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                # Handle both list and dict-like json\n",
    "                self.cold_users = set(data if isinstance(data, list) else data[0])\n",
    "        except:\n",
    "            self.cold_users = set()\n",
    "\n",
    "        self._preprocess_features()\n",
    "        self._train_hybrid_model()\n",
    "\n",
    "    def _preprocess_features(self):\n",
    "        # 1. Parse Equipment and Products safely\n",
    "        def parse_set(x, is_dict=False):\n",
    "            try:\n",
    "                val = ast.literal_eval(x)\n",
    "                if is_dict: return set(val.keys())\n",
    "                return set(val)\n",
    "            except: return set()\n",
    "\n",
    "        self.recipes['required_equipment_set'] = self.recipes['required_equipment'].apply(lambda x: parse_set(x))\n",
    "        self.recipes['required_products_set'] = self.recipes['required_products'].apply(lambda x: parse_set(x, True))\n",
    "        self.users['owned_equipment_set'] = self.users['owned_equipment'].apply(lambda x: parse_set(x))\n",
    "        self.users['available_products_set'] = self.users['available_products'].apply(lambda x: parse_set(x))\n",
    "\n",
    "        # 2. Taste Features Matrix\n",
    "        self.taste_features = ['bitterness', 'sweetness', 'acidity', 'body']\n",
    "        self.recipe_taste_matrix = self.recipes[['taste_' + f for f in self.taste_features]].values\n",
    "\n",
    "        # 3. Indexing\n",
    "        self.users.set_index('user_id', inplace=True, drop=False)\n",
    "\n",
    "        # 4. Global Stats\n",
    "        self.global_mean = self.interactions['rating'].mean()\n",
    "        self.recipe_popularity = self.interactions.groupby('recipe_id')['rating'].mean().to_dict()\n",
    "\n",
    "    def _train_hybrid_model(self):\n",
    "        # --- A. Collaborative Filtering (SVD) ---\n",
    "        # Use only explicit ratings for cleaner signal\n",
    "        train_data = self.interactions.dropna(subset=['rating'])\n",
    "\n",
    "        # Calculate Biases\n",
    "        user_means = train_data.groupby('user_id')['rating'].mean()\n",
    "        item_means = train_data.groupby('recipe_id')['rating'].mean()\n",
    "\n",
    "        self.user_bias = (user_means - self.global_mean).to_dict()\n",
    "        self.item_bias = (item_means - self.global_mean).to_dict()\n",
    "\n",
    "        # Calculate Residuals\n",
    "        train_data['residual'] = (train_data['rating'] - self.global_mean -\n",
    "                                  train_data['user_id'].map(self.user_bias) -\n",
    "                                  train_data['recipe_id'].map(self.item_bias))\n",
    "\n",
    "        # Factorization\n",
    "        self.rating_matrix = train_data.pivot_table(\n",
    "            index='user_id', columns='recipe_id', values='residual'\n",
    "        ).fillna(0)\n",
    "\n",
    "        self.svd = TruncatedSVD(n_components=20, random_state=42)\n",
    "        self.user_factors = self.svd.fit_transform(self.rating_matrix)\n",
    "        self.item_factors = self.svd.components_\n",
    "\n",
    "        # Mappings\n",
    "        self.user_id_map = {uid: i for i, uid in enumerate(self.rating_matrix.index)}\n",
    "        self.recipe_ids_cf = self.rating_matrix.columns.tolist()\n",
    "        self.cf_recipe_indices = {rid: i for i, rid in enumerate(self.recipe_ids_cf)}\n",
    "\n",
    "        # --- B. History-Based Content Profiling ---\n",
    "        # Instead of trusting sign-up preferences, build profile from what they actually liked (>= 4.0)\n",
    "        good_interactions = train_data[train_data['rating'] >= 4.0]\n",
    "        merged = good_interactions.merge(self.recipes, on='recipe_id')\n",
    "        self.user_history_profiles = merged.groupby('user_id')[\n",
    "            ['taste_' + f for f in self.taste_features]\n",
    "        ].mean()\n",
    "\n",
    "    def _get_content_scores(self, user_id, feasible_ids):\n",
    "        # 1. Determine User Taste Vector\n",
    "        if user_id in self.user_history_profiles.index:\n",
    "            # Warm: Use learned history profile\n",
    "            u_vec = self.user_history_profiles.loc[user_id].values.reshape(1, -1)\n",
    "        else:\n",
    "            # Cold: Use stated preference\n",
    "            try:\n",
    "                u_vec = self.users.loc[user_id, ['taste_pref_' + f for f in self.taste_features]].values.reshape(1, -1)\n",
    "            except:\n",
    "                return {} # User not found\n",
    "\n",
    "        # 2. Get Recipe Vectors for Feasible Items\n",
    "        # Map feasible IDs to their index in the main recipe dataframe\n",
    "        recipe_indices = [self.recipes[self.recipes['recipe_id'] == rid].index[0] for rid in feasible_ids]\n",
    "        r_vecs = self.recipe_taste_matrix[recipe_indices]\n",
    "\n",
    "        # 3. Calculate Similarity & Scale to Rating (1-5)\n",
    "        sims = cosine_similarity(u_vec, r_vecs)[0]\n",
    "        # Map cosine (-1 to 1) to approx rating (1 to 5)\n",
    "        # Formula: 1 + 2 * (sim + 1) -> -1=>1, 0=>3, 1=>5\n",
    "        scores = 1 + 2 * (sims + 1)\n",
    "\n",
    "        return dict(zip(feasible_ids, scores))\n",
    "\n",
    "    def recommend(self, user_id, n_recommendations=5):\n",
    "        # --- 1. Feasibility Filter ---\n",
    "        try:\n",
    "            user_row = self.users.loc[user_id]\n",
    "        except KeyError:\n",
    "            return []\n",
    "\n",
    "        u_equip = user_row['owned_equipment_set']\n",
    "        u_prods = user_row['available_products_set']\n",
    "\n",
    "        # Find feasible recipes\n",
    "        # Note: Iterate is fast enough for <1000 recipes. Vectorize for larger catalogs.\n",
    "        feasible_ids = []\n",
    "        for idx, row in self.recipes.iterrows():\n",
    "            if row['required_equipment_set'].issubset(u_equip) and row['required_products_set'].issubset(u_prods):\n",
    "                feasible_ids.append(row['recipe_id'])\n",
    "\n",
    "        if not feasible_ids:\n",
    "            return []\n",
    "\n",
    "        # --- 2. Scoring ---\n",
    "        scores = {}\n",
    "        is_warm = user_id in self.user_id_map\n",
    "\n",
    "        # Base Content Score (Calculated for everyone)\n",
    "        content_scores = self._get_content_scores(user_id, feasible_ids)\n",
    "\n",
    "        if is_warm:\n",
    "            # --- Warm Strategy: Hybrid (SVD + Content) ---\n",
    "            u_idx = self.user_id_map[user_id]\n",
    "            pred_residuals = np.dot(self.user_factors[u_idx], self.item_factors)\n",
    "            u_bias = self.user_bias.get(user_id, 0)\n",
    "\n",
    "            # Weighting: 60% Collaborative, 40% Content\n",
    "            alpha = 0.6\n",
    "\n",
    "            for rid in feasible_ids:\n",
    "                # Calculate SVD component\n",
    "                if rid in self.cf_recipe_indices:\n",
    "                    idx = self.cf_recipe_indices[rid]\n",
    "                    svd_val = self.global_mean + u_bias + self.item_bias.get(rid, 0) + pred_residuals[idx]\n",
    "                else:\n",
    "                    # New item not in matrix\n",
    "                    svd_val = self.global_mean + u_bias + self.item_bias.get(rid, 0)\n",
    "\n",
    "                # Blend\n",
    "                c_val = content_scores.get(rid, 3.0)\n",
    "                scores[rid] = alpha * svd_val + (1 - alpha) * c_val\n",
    "\n",
    "        else:\n",
    "            # --- Cold Strategy: Content + Popularity Boost ---\n",
    "            for rid in feasible_ids:\n",
    "                c_val = content_scores.get(rid, 3.0)\n",
    "                pop_val = self.recipe_popularity.get(rid, 3.0) # Default to 3.0 (neutral)\n",
    "\n",
    "                # Add small boost for popular items (0.1 weight)\n",
    "                # Normalize pop_val (1-5) roughly to 0-1 for the boost magnitude\n",
    "                scores[rid] = c_val + 0.1 * (pop_val / 5.0)\n",
    "\n",
    "        # --- 3. Ranking ---\n",
    "        sorted_recs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_ids = [x[0] for x in sorted_recs[:n_recommendations]]\n",
    "\n",
    "        # Return formatted list\n",
    "        return top_ids\n",
    "\n",
    "# --- Evaluation Script ---\n",
    "def calculate_ndcg(recommender, val_df, k=5):\n",
    "    \"\"\"Calculates average NDCG@k for the validation set.\"\"\"\n",
    "    ndcg_scores = []\n",
    "\n",
    "    # Group ground truth by user\n",
    "    gt = val_df.groupby('user_id').apply(\n",
    "        lambda x: dict(zip(x['recipe_id'], x['rating']))\n",
    "    ).to_dict()\n",
    "\n",
    "    for uid, ratings in gt.items():\n",
    "        # Clean ratings (ignore NaNs)\n",
    "        ratings = {k: v for k, v in ratings.items() if pd.notnull(v)}\n",
    "        if not ratings: continue\n",
    "\n",
    "        # Get Recommendations\n",
    "        recs = recommender.recommend(uid, n_recommendations=k)\n",
    "        if not recs:\n",
    "            ndcg_scores.append(0)\n",
    "            continue\n",
    "\n",
    "        # Relevance vector\n",
    "        rel = [ratings.get(rid, 0) for rid in recs]\n",
    "\n",
    "        # Ideal Relevance (Top K ratings from ground truth)\n",
    "        ideal = sorted(ratings.values(), reverse=True)[:k]\n",
    "\n",
    "        # DCG & IDCG\n",
    "        dcg = sum([r / np.log2(i+2) for i, r in enumerate(rel)])\n",
    "        idcg = sum([r / np.log2(i+2) for i, r in enumerate(ideal)])\n",
    "\n",
    "        if idcg > 0:\n",
    "            ndcg_scores.append(dcg / idcg)\n",
    "        else:\n",
    "            ndcg_scores.append(0)\n",
    "\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "# --- Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize\n",
    "    rec_engine = CoffeeRecommender('recipes.csv', 'users.csv', 'interactions_train.csv', 'cold_users.json')\n",
    "\n",
    "    # Load Validation Sets\n",
    "    val_warm = pd.read_csv('interactions_val.csv')\n",
    "    val_cold = pd.read_csv('interactions_val_cold.csv')\n",
    "\n",
    "    print(\"--- Evaluation Results ---\")\n",
    "\n",
    "    # Warm Evaluation\n",
    "    # We use a sample of 5000 for speed, remove .head() for full eval\n",
    "    score_warm = calculate_ndcg(rec_engine, val_warm.head(5000), k=5)\n",
    "    print(f\"Warm Users NDCG@5: {score_warm:.4f}\")\n",
    "\n",
    "    # Cold Evaluation\n",
    "    score_cold = calculate_ndcg(rec_engine, val_cold.head(5000), k=5)\n",
    "    print(f\"Cold Users NDCG@5: {score_cold:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation Results ---\n",
      "Warm Users NDCG@5: 0.3079\n",
      "Cold Users NDCG@5: 0.3539\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T16:13:39.793850900Z",
     "start_time": "2026-01-27T16:13:35.531028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class TwoTowerNCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32):\n",
    "        super(TwoTowerNCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        self.user_tower = nn.Sequential(\n",
    "            nn.Linear(embedding_dim + 4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "\n",
    "        self.item_tower = nn.Sequential(\n",
    "            nn.Linear(embedding_dim + 4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_ids, user_features, item_ids, item_features):\n",
    "        u_emb = self.user_embedding(user_ids)\n",
    "        u_input = torch.cat([u_emb, user_features], dim=1)\n",
    "        u_vec = self.user_tower(u_input)\n",
    "\n",
    "        i_emb = self.item_embedding(item_ids)\n",
    "        i_input = torch.cat([i_emb, item_features], dim=1)\n",
    "        i_vec = self.item_tower(i_input)\n",
    "\n",
    "        return torch.sum(u_vec * i_vec, dim=1)\n",
    "\n",
    "class DeepCoffeeRecommender:\n",
    "    def __init__(self, recipes_path, users_path, train_path, cold_users_path):\n",
    "        self.recipes = pd.read_csv(recipes_path)\n",
    "        self.users = pd.read_csv(users_path)\n",
    "        self.interactions = pd.read_csv(train_path)\n",
    "\n",
    "        self._prepare_data()\n",
    "        self._build_model()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        for df, col, is_dict in [(self.recipes, 'required_equipment', False),\n",
    "                                 (self.recipes, 'required_products', True),\n",
    "                                 (self.users, 'owned_equipment', False),\n",
    "                                 (self.users, 'available_products', False)]:\n",
    "            def parse(x):\n",
    "                try:\n",
    "                    v = ast.literal_eval(x)\n",
    "                    return set(v.keys()) if is_dict else set(v)\n",
    "                except: return set()\n",
    "            df[f'{col}_set'] = df[col].apply(parse)\n",
    "\n",
    "        self.user_map = {uid: i for i, uid in enumerate(self.users['user_id'].unique())}\n",
    "        self.item_map = {rid: i for i, rid in enumerate(self.recipes['recipe_id'].unique())}\n",
    "        self.inv_item_map = {i: rid for rid, i in self.item_map.items()}\n",
    "\n",
    "        self.taste_cols = ['bitterness', 'sweetness', 'acidity', 'body']\n",
    "        self.u_taste_cols = ['taste_pref_' + c for c in self.taste_cols]\n",
    "        self.i_taste_cols = ['taste_' + c for c in self.taste_cols]\n",
    "\n",
    "    def _build_model(self):\n",
    "        self.model = TwoTowerNCF(len(self.user_map), len(self.item_map))\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "    def train_step(self, epochs=5):\n",
    "        train_df = self.interactions.dropna(subset=['rating'])\n",
    "        self.model.train()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            u_ids = torch.tensor([self.user_map[uid] for uid in train_df['user_id']], dtype=torch.long)\n",
    "            i_ids = torch.tensor([self.item_map[rid] for rid in train_df['recipe_id']], dtype=torch.long)\n",
    "\n",
    "            u_feats = torch.tensor(self.users.set_index('user_id').loc[train_df['user_id'], self.u_taste_cols].values, dtype=torch.float)\n",
    "            i_feats = torch.tensor(self.recipes.set_index('recipe_id').loc[train_df['recipe_id'], self.i_taste_cols].values, dtype=torch.float)\n",
    "            ratings = torch.tensor(train_df['rating'].values, dtype=torch.float)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            preds = self.model(u_ids, u_feats, i_ids, i_feats)\n",
    "            loss = F.mse_loss(preds, ratings)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def recommend(self, user_id, n=5):\n",
    "        self.model.eval()\n",
    "        u_row = self.users[self.users['user_id'] == user_id].iloc[0]\n",
    "\n",
    "        feasible = []\n",
    "        for _, row in self.recipes.iterrows():\n",
    "            if row['required_equipment_set'].issubset(u_row['owned_equipment_set']) and \\\n",
    "               row['required_products_set'].issubset(u_row['available_products_set']):\n",
    "                feasible.append(row['recipe_id'])\n",
    "\n",
    "        if not feasible: return []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            u_idx = torch.tensor([self.user_map[user_id]], dtype=torch.long)\n",
    "            u_feat = torch.tensor(u_row[self.u_taste_cols].values.reshape(1,-1), dtype=torch.float)\n",
    "\n",
    "            i_idxs = torch.tensor([self.item_map[rid] for rid in feasible], dtype=torch.long)\n",
    "            i_feats = torch.tensor(self.recipes.set_index('recipe_id').loc[feasible, self.i_taste_cols].values, dtype=torch.float)\n",
    "\n",
    "            # Broadcast user to match feasible items\n",
    "            u_idx_rep = u_idx.repeat(len(feasible))\n",
    "            u_feat_rep = u_feat.repeat(len(feasible), 1)\n",
    "\n",
    "            scores = self.model(u_idx_rep, u_feat_rep, i_idxs, i_feats)\n",
    "\n",
    "        results = sorted(zip(feasible, scores.numpy()), key=lambda x: x[1], reverse=True)\n",
    "        return [r[0] for r in results[:n]]\n",
    "\n",
    "def evaluate_ndcg(rec_sys, val_df, k=5):\n",
    "    scores = []\n",
    "    gt = val_df.groupby('user_id').apply(lambda x: dict(zip(x['recipe_id'], x['rating']))).to_dict()\n",
    "\n",
    "    for uid, ratings in gt.items():\n",
    "        ratings = {k: v for k, v in ratings.items() if pd.notnull(v)}\n",
    "        if not ratings: continue\n",
    "\n",
    "        recs = rec_sys.recommend(uid, n=k)\n",
    "        if not recs:\n",
    "            scores.append(0); continue\n",
    "\n",
    "        rel = [ratings.get(r, 0) for r in recs]\n",
    "        ideal = sorted(ratings.values(), reverse=True)[:k]\n",
    "\n",
    "        dcg = sum([r / np.log2(i+2) for i, r in enumerate(rel)])\n",
    "        idcg = sum([r / np.log2(i+2) for i, r in enumerate(ideal)])\n",
    "        scores.append(dcg/idcg if idcg > 0 else 0)\n",
    "    return np.mean(scores)\n"
   ],
   "id": "46917a763577c9a4",
   "outputs": [],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
