{
 "cells": [
  {
   "cell_type": "code",
   "id": "bf348720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:52:34.240334600Z",
     "start_time": "2026-01-29T16:52:20.620406500Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "be180762",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:52:34.256118900Z",
     "start_time": "2026-01-29T16:52:34.244452800Z"
    }
   },
   "source": [
    "class CoffeeDataset(Dataset):\n",
    "    def __init__(self, interactions, recipes, users):\n",
    "        \n",
    "        self.user_map = users.set_index('user_id')[['taste_pref_bitterness', 'taste_pref_sweetness', 'taste_pref_acidity', 'taste_pref_body']].T.to_dict('list')\n",
    "        self.recipe_map = recipes.set_index('recipe_id')[['taste_bitterness', 'taste_sweetness', 'taste_acidity', 'taste_body']].T.to_dict('list')\n",
    "\n",
    "        valid_interactions = []\n",
    "        for _, row in interactions.iterrows():\n",
    "            if row['user_id'] in self.user_map and row['recipe_id'] in self.recipe_map:\n",
    "                valid_interactions.append(row)\n",
    "        \n",
    "        self.data = pd.DataFrame(valid_interactions)\n",
    "        self.u_ids = self.data['user_id'].values\n",
    "        self.r_ids = self.data['recipe_id'].values\n",
    "        \n",
    "        self.targets = (self.data['rating'].values / 5.0).astype(np.float32)\n",
    "        self.raw_ratings = self.data['rating'].values.astype(np.float32)\n",
    "\n",
    "    def __len__(self): return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u_feat = np.array(self.user_map[self.u_ids[idx]], dtype=np.float32)\n",
    "        r_feat = np.array(self.recipe_map[self.r_ids[idx]], dtype=np.float32)\n",
    "        return u_feat, r_feat, self.targets[idx], self.raw_ratings[idx]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "d2cb1861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:52:34.268861700Z",
     "start_time": "2026-01-29T16:52:34.260124700Z"
    }
   },
   "source": [
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, user_dim=4, item_dim=4, embedding_dim=32): \n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "        self.user_mlp = nn.Sequential(\n",
    "            nn.Linear(user_dim, 128),   \n",
    "            nn.BatchNorm1d(128),          \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),           \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        self.item_mlp = nn.Sequential(\n",
    "            nn.Linear(item_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_features, item_features):\n",
    "        user_embedding = self.user_mlp(user_features)\n",
    "        item_embedding = self.item_mlp(item_features)\n",
    "        \n",
    "        score = (user_embedding * item_embedding).sum(dim=1)\n",
    "        return user_embedding, item_embedding\n",
    "        # return torch.sigmoid(score)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "28dd11ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:52:34.284714200Z",
     "start_time": "2026-01-29T16:52:34.272368300Z"
    }
   },
   "source": [
    "def evaluate_ndcg(model, val_df, recipes, users, k=5):\n",
    "    model.eval()\n",
    "    user_ndcgs = []\n",
    "    \n",
    "    u_map = users.set_index('user_id')[['taste_pref_bitterness', 'taste_pref_sweetness', 'taste_pref_acidity', 'taste_pref_body']].T.to_dict('list')\n",
    "    r_map = recipes.set_index('recipe_id')[['taste_bitterness', 'taste_sweetness', 'taste_acidity', 'taste_body']].T.to_dict('list')\n",
    "    \n",
    "    valid_val_df = val_df[val_df['user_id'].isin(u_map.keys()) & val_df['recipe_id'].isin(r_map.keys())]\n",
    "    grouped = valid_val_df.groupby('user_id')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user_id, group in grouped:\n",
    "            if len(group) < 2: continue\n",
    "            \n",
    "            u_feat = torch.tensor([u_map[user_id]] * len(group), dtype=torch.float32)\n",
    "            r_feat = torch.tensor([r_map[r] for r in group['recipe_id'].values], dtype=torch.float32)\n",
    "            \n",
    "            true_ratings = torch.tensor(group['rating'].values, dtype=torch.float32)\n",
    "            \n",
    "            preds = model(u_feat, r_feat)\n",
    "            \n",
    "            _, indices = torch.sort(preds, descending=True)\n",
    "            relevance_at_k = true_ratings[indices[:k]]\n",
    "            \n",
    "            ideal_relevance, _ = torch.sort(true_ratings, descending=True)\n",
    "            ideal_relevance = ideal_relevance[:k]\n",
    "            \n",
    "            discounts = torch.log2(torch.arange(2, len(relevance_at_k) + 2).float())\n",
    "            dcg = torch.sum(relevance_at_k / discounts)\n",
    "            idcg = torch.sum(ideal_relevance / discounts)\n",
    "            \n",
    "            ndcg = (dcg / idcg) if idcg > 0 else torch.tensor(0.0)\n",
    "            user_ndcgs.append(ndcg.item())\n",
    "            \n",
    "    return np.mean(user_ndcgs) if user_ndcgs else 0.0"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "354a79ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:52:34.566557600Z",
     "start_time": "2026-01-29T16:52:34.284714200Z"
    }
   },
   "source": [
    "\n",
    "users_df = pd.read_csv('../student_data/users.csv').fillna(0)\n",
    "recipes_df = pd.read_csv('../student_data/recipes.csv').fillna(0)\n",
    "interactions_df = pd.read_csv('../student_data/interactions_train.csv').fillna(2.5)\n",
    "val_csv = pd.read_csv('../student_data/interactions_val.csv').fillna(2.5)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "6c701385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:52:39.115767Z",
     "start_time": "2026-01-29T16:52:34.570572500Z"
    }
   },
   "source": [
    "train_df, internal_val = train_test_split(interactions_df, test_size=0.1, random_state=42)\n",
    "    \n",
    "train_dataset = CoffeeDataset(train_df, recipes_df, users_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "c0314bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:52:41.684947200Z",
     "start_time": "2026-01-29T16:52:39.585809Z"
    }
   },
   "source": [
    "model = TwoTowerModel(user_dim=4, item_dim=4, embedding_dim=32)\n",
    "    \n",
    "criterion = nn.MarginRankingLoss(margin=0.2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "9d66951d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:52:41.726512200Z",
     "start_time": "2026-01-29T16:52:41.707727800Z"
    }
   },
   "source": [
    "def evaluate_ndcg(model, val_df, recipes, users, k=5):\n",
    "    model.eval()\n",
    "    user_ndcgs = []\n",
    "    \n",
    "    u_map = users.set_index('user_id')[['taste_pref_bitterness', 'taste_pref_sweetness', 'taste_pref_acidity', 'taste_pref_body']].T.to_dict('list')\n",
    "    r_map = recipes.set_index('recipe_id')[['taste_bitterness', 'taste_sweetness', 'taste_acidity', 'taste_body']].T.to_dict('list')\n",
    "    \n",
    "    valid_val_df = val_df[val_df['user_id'].isin(u_map.keys()) & val_df['recipe_id'].isin(r_map.keys())]\n",
    "    grouped = valid_val_df.groupby('user_id')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user_id, group in grouped:\n",
    "            if len(group) < 2: continue\n",
    "            \n",
    "            u_feat = torch.tensor([u_map[user_id]] * len(group), dtype=torch.float32)\n",
    "            r_feat = torch.tensor([r_map[r] for r in group['recipe_id'].values], dtype=torch.float32)\n",
    "            \n",
    "            true_ratings = torch.tensor(group['rating'].values, dtype=torch.float32)\n",
    "\n",
    "            # 1. Unpack the embeddings (tuple)\n",
    "            u_emb, r_emb = model(u_feat, r_feat)\n",
    "            \n",
    "            # 2. Calculate the score (Dot Product) manually\n",
    "            preds = (u_emb * r_emb).sum(dim=1)\n",
    "            \n",
    "            _, indices = torch.sort(preds, descending=True)\n",
    "            relevance_at_k = true_ratings[indices[:k]]\n",
    "            \n",
    "            ideal_relevance, _ = torch.sort(true_ratings, descending=True)\n",
    "            ideal_relevance = ideal_relevance[:k]\n",
    "            \n",
    "            discounts = torch.log2(torch.arange(2, len(relevance_at_k) + 2).float())\n",
    "            dcg = torch.sum(relevance_at_k / discounts)\n",
    "            idcg = torch.sum(ideal_relevance / discounts)\n",
    "            \n",
    "            ndcg = (dcg / idcg) if idcg > 0 else torch.tensor(0.0)\n",
    "            user_ndcgs.append(ndcg.item())\n",
    "            \n",
    "    return np.mean(user_ndcgs) if user_ndcgs else 0.0"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "0dcdca9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:54:40.026915300Z",
     "start_time": "2026-01-29T16:52:41.730724Z"
    }
   },
   "source": [
    "# Setup Optimizer and Loss\n",
    "model = TwoTowerModel(user_dim=4, item_dim=4, embedding_dim=32)\n",
    "criterion = nn.MarginRankingLoss(margin=0.2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Training MLP on {len(train_df)} samples...\")\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for u_feat, r_feat, _, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 1. Forward pass for Positive pairs (User + Actual Recipe)\n",
    "        user_emb, pos_item_emb = model(u_feat, r_feat)\n",
    "        \n",
    "        # 2. Create Negative pairs (In-batch Negative Sampling)\n",
    "        # We shuffle the recipe features in the current batch to create mismatches\n",
    "        random_indices = torch.randperm(r_feat.size(0))\n",
    "        neg_r_feat = r_feat[random_indices]\n",
    "        \n",
    "        # 3. Forward pass for Negative pairs (User + Random Recipe)\n",
    "        # We don't need the user_emb again, just the negative item embedding\n",
    "        _, neg_item_emb = model(u_feat, neg_r_feat)\n",
    "\n",
    "        # 4. Calculate Scores (Dot Product)\n",
    "        pos_scores = (user_emb * pos_item_emb).sum(dim=1)\n",
    "        neg_scores = (user_emb * neg_item_emb).sum(dim=1)\n",
    "\n",
    "        # 5. Calculate Loss\n",
    "        # Target is 1s because we want pos_scores > neg_scores\n",
    "        target = torch.ones(u_feat.size(0)) \n",
    "        \n",
    "        loss = criterion(pos_scores, neg_scores, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()   \n",
    "\n",
    "    # Validation\n",
    "    val_ndcg = evaluate_ndcg(model, internal_val, recipes_df, users_df)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Train-Val NDCG: {val_ndcg:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP on 68305 samples...\n",
      "Epoch 1 | Loss: 0.1846 | Train-Val NDCG: 0.9054\n",
      "Epoch 2 | Loss: 0.1553 | Train-Val NDCG: 0.9065\n",
      "Epoch 3 | Loss: 0.1499 | Train-Val NDCG: 0.9047\n",
      "Epoch 4 | Loss: 0.1468 | Train-Val NDCG: 0.9039\n",
      "Epoch 5 | Loss: 0.1454 | Train-Val NDCG: 0.9048\n",
      "Epoch 6 | Loss: 0.1419 | Train-Val NDCG: 0.9069\n",
      "Epoch 7 | Loss: 0.1401 | Train-Val NDCG: 0.9069\n",
      "Epoch 8 | Loss: 0.1371 | Train-Val NDCG: 0.9060\n",
      "Epoch 9 | Loss: 0.1356 | Train-Val NDCG: 0.9055\n",
      "Epoch 10 | Loss: 0.1354 | Train-Val NDCG: 0.9063\n",
      "Epoch 11 | Loss: 0.1336 | Train-Val NDCG: 0.9058\n",
      "Epoch 12 | Loss: 0.1332 | Train-Val NDCG: 0.9073\n",
      "Epoch 13 | Loss: 0.1313 | Train-Val NDCG: 0.9056\n",
      "Epoch 14 | Loss: 0.1307 | Train-Val NDCG: 0.9055\n",
      "Epoch 15 | Loss: 0.1288 | Train-Val NDCG: 0.9068\n",
      "Epoch 16 | Loss: 0.1291 | Train-Val NDCG: 0.9072\n",
      "Epoch 17 | Loss: 0.1287 | Train-Val NDCG: 0.9061\n",
      "Epoch 18 | Loss: 0.1266 | Train-Val NDCG: 0.9065\n",
      "Epoch 19 | Loss: 0.1270 | Train-Val NDCG: 0.9056\n",
      "Epoch 20 | Loss: 0.1257 | Train-Val NDCG: 0.9069\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "f77d8eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:54:40.148659200Z",
     "start_time": "2026-01-29T16:54:40.107719200Z"
    }
   },
   "source": [
    "torch.save(model.state_dict(), '../model_weights.pth')"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "0a729f60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:54:41.200985600Z",
     "start_time": "2026-01-29T16:54:40.160639800Z"
    }
   },
   "source": [
    "final_ndcg = evaluate_ndcg(model, val_csv, recipes_df, users_df)\n",
    "print(f\"FINAL NDCG (Provided Val Set): {final_ndcg:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL NDCG (Provided Val Set): 0.8118\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "b9c4d074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:54:41.511934200Z",
     "start_time": "2026-01-29T16:54:41.238318800Z"
    }
   },
   "source": [
    "val_cold_csv = pd.read_csv('../student_data/interactions_val_cold.csv').fillna(0)\n",
    "\n",
    "final_ndcg = evaluate_ndcg(model, val_cold_csv, recipes_df, users_df)\n",
    "print(f\"FINAL NDCG (Provided Val Cold Set): {final_ndcg:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL NDCG (Provided Val Cold Set): 0.6014\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
