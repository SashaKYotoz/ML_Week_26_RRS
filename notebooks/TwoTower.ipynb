{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf348720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be180762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoffeeDataset(Dataset):\n",
    "    def __init__(self, interactions, recipes, users):\n",
    "        \n",
    "        self.user_map = users.set_index('user_id')[['taste_pref_bitterness', 'taste_pref_sweetness', 'taste_pref_acidity', 'taste_pref_body']].T.to_dict('list')\n",
    "        self.recipe_map = recipes.set_index('recipe_id')[['taste_bitterness', 'taste_sweetness', 'taste_acidity', 'taste_body']].T.to_dict('list')\n",
    "        \n",
    "        valid_interactions = []\n",
    "        for _, row in interactions.iterrows():\n",
    "            if row['user_id'] in self.user_map and row['recipe_id'] in self.recipe_map:\n",
    "                valid_interactions.append(row)\n",
    "        \n",
    "        self.data = pd.DataFrame(valid_interactions)\n",
    "        self.u_ids = self.data['user_id'].values\n",
    "        self.r_ids = self.data['recipe_id'].values\n",
    "        \n",
    "        self.targets = (self.data['rating'].values / 5.0).astype(np.float32)\n",
    "        self.raw_ratings = self.data['rating'].values.astype(np.float32)\n",
    "\n",
    "    def __len__(self): return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u_feat = np.array(self.user_map[self.u_ids[idx]], dtype=np.float32)\n",
    "        r_feat = np.array(self.recipe_map[self.r_ids[idx]], dtype=np.float32)\n",
    "        return u_feat, r_feat, self.targets[idx], self.raw_ratings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2cb1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, user_dim=4, item_dim=4, embedding_dim=32): \n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        \n",
    "        self.user_mlp = nn.Sequential(\n",
    "            nn.Linear(user_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, embedding_dim)  \n",
    "        )\n",
    "        \n",
    "        self.item_mlp = nn.Sequential(\n",
    "            nn.Linear(item_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_features, item_features):\n",
    "        user_embedding = self.user_mlp(user_features)\n",
    "        item_embedding = self.item_mlp(item_features)\n",
    "        \n",
    "        score = (user_embedding * item_embedding).sum(dim=1)\n",
    "        \n",
    "        return torch.sigmoid(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28dd11ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ndcg(model, val_df, recipes, users, k=5):\n",
    "    model.eval()\n",
    "    user_ndcgs = []\n",
    "    \n",
    "    u_map = users.set_index('user_id')[['taste_pref_bitterness', 'taste_pref_sweetness', 'taste_pref_acidity', 'taste_pref_body']].T.to_dict('list')\n",
    "    r_map = recipes.set_index('recipe_id')[['taste_bitterness', 'taste_sweetness', 'taste_acidity', 'taste_body']].T.to_dict('list')\n",
    "    \n",
    "    valid_val_df = val_df[val_df['user_id'].isin(u_map.keys()) & val_df['recipe_id'].isin(r_map.keys())]\n",
    "    grouped = valid_val_df.groupby('user_id')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user_id, group in grouped:\n",
    "            if len(group) < 2: continue\n",
    "            \n",
    "            u_feat = torch.tensor([u_map[user_id]] * len(group), dtype=torch.float32)\n",
    "            r_feat = torch.tensor([r_map[r] for r in group['recipe_id'].values], dtype=torch.float32)\n",
    "            \n",
    "            true_ratings = torch.tensor(group['rating'].values, dtype=torch.float32)\n",
    "            \n",
    "            preds = model(u_feat, r_feat)\n",
    "            \n",
    "            _, indices = torch.sort(preds, descending=True)\n",
    "            relevance_at_k = true_ratings[indices[:k]]\n",
    "            \n",
    "            ideal_relevance, _ = torch.sort(true_ratings, descending=True)\n",
    "            ideal_relevance = ideal_relevance[:k]\n",
    "            \n",
    "            discounts = torch.log2(torch.arange(2, len(relevance_at_k) + 2).float())\n",
    "            dcg = torch.sum(relevance_at_k / discounts)\n",
    "            idcg = torch.sum(ideal_relevance / discounts)\n",
    "            \n",
    "            ndcg = (dcg / idcg) if idcg > 0 else torch.tensor(0.0)\n",
    "            user_ndcgs.append(ndcg.item())\n",
    "            \n",
    "    return np.mean(user_ndcgs) if user_ndcgs else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "354a79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "users_df = pd.read_csv('../student_data/users.csv').fillna(0)\n",
    "recipes_df = pd.read_csv('../student_data/recipes.csv').fillna(0)\n",
    "interactions_df = pd.read_csv('../student_data/interactions_train.csv').fillna(2.5)\n",
    "val_csv = pd.read_csv('../student_data/interactions_val.csv').fillna(2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c701385",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, internal_val = train_test_split(interactions_df, test_size=0.1, random_state=42)\n",
    "    \n",
    "train_dataset = CoffeeDataset(train_df, recipes_df, users_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0314bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoTowerModel(user_dim=4, item_dim=4, embedding_dim=32)\n",
    "    \n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3998cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP on 68305 samples...\n",
      "Epoch 1 | Loss: 0.0342 | Train-Val NDCG: 0.9039\n",
      "Epoch 2 | Loss: 0.0337 | Train-Val NDCG: 0.9043\n",
      "Epoch 3 | Loss: 0.0335 | Train-Val NDCG: 0.9062\n",
      "Epoch 4 | Loss: 0.0333 | Train-Val NDCG: 0.9061\n",
      "Epoch 5 | Loss: 0.0332 | Train-Val NDCG: 0.9058\n",
      "Epoch 6 | Loss: 0.0331 | Train-Val NDCG: 0.9051\n",
      "Epoch 7 | Loss: 0.0331 | Train-Val NDCG: 0.9094\n",
      "Epoch 8 | Loss: 0.0330 | Train-Val NDCG: 0.9076\n",
      "Epoch 9 | Loss: 0.0330 | Train-Val NDCG: 0.9109\n",
      "Epoch 10 | Loss: 0.0329 | Train-Val NDCG: 0.9079\n",
      "Epoch 11 | Loss: 0.0329 | Train-Val NDCG: 0.9082\n",
      "Epoch 12 | Loss: 0.0329 | Train-Val NDCG: 0.9077\n",
      "Epoch 13 | Loss: 0.0328 | Train-Val NDCG: 0.9089\n",
      "Epoch 14 | Loss: 0.0328 | Train-Val NDCG: 0.9082\n",
      "Epoch 15 | Loss: 0.0327 | Train-Val NDCG: 0.9084\n",
      "Epoch 16 | Loss: 0.0327 | Train-Val NDCG: 0.9103\n",
      "Epoch 17 | Loss: 0.0327 | Train-Val NDCG: 0.9095\n",
      "Epoch 18 | Loss: 0.0327 | Train-Val NDCG: 0.9101\n",
      "Epoch 19 | Loss: 0.0326 | Train-Val NDCG: 0.9104\n",
      "Epoch 20 | Loss: 0.0326 | Train-Val NDCG: 0.9101\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training MLP on {len(train_df)} samples...\")\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for u_feat, r_feat, target, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(u_feat, r_feat)\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()   \n",
    "    \n",
    "    val_ndcg = evaluate_ndcg(model, internal_val, recipes_df, users_df)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Train-Val NDCG: {val_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f77d8eda",
   "metadata": {},
   "outputs": [],
   "source": "torch.save(model.state_dict(), '../model_weights.pth')"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a729f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL NDCG (Provided Val Set): 0.8173\n"
     ]
    }
   ],
   "source": [
    "final_ndcg = evaluate_ndcg(model, val_csv, recipes_df, users_df)\n",
    "print(f\"FINAL NDCG (Provided Val Set): {final_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9c4d074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL NDCG (Provided Val Cold Set): 0.6107\n"
     ]
    }
   ],
   "source": [
    "val_cold_csv = pd.read_csv('../student_data/interactions_val_cold.csv').fillna(0)\n",
    "\n",
    "final_ndcg = evaluate_ndcg(model, val_cold_csv, recipes_df, users_df)\n",
    "print(f\"FINAL NDCG (Provided Val Cold Set): {final_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219afcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
